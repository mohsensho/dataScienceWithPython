{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "### import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311 = pd.read_csv ('Datasets/311_Service_Requests_from_2010_to_Present.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. . Understand the dataset:\n",
    "#   1.1 Import the dataset\n",
    "#   1.2 Visualize the dataset\n",
    "#   1.3 Print the columns of the DataFrame 1.4 Identify the shape of the dataset\n",
    "#   1.5 Identify the variables with null values\n",
    "\n",
    "df_311.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_311.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2. Perform basic data exploratory analysis:\n",
    "#   2.1 Draw a frequency plot to show the number of null values in each column of the DataFrame\n",
    "#   2.2 Missing value treatment\n",
    "#   2.2.1 Remove the records whose Closed Date values are null\n",
    "#    2.3 Analyze the date column, and remove entries that have an incorrect timeline\n",
    "#   2.3.1 Calculate the time elapsed in closed and creation date\n",
    "#   2.3.2 Convert the calculated date to seconds to get a better representation\n",
    "#   2.3.3 View the descriptive statistics for the newly created column\n",
    "#   2.3.4 Check the number of null values in the Complaint_Type and City columns\n",
    "#   2.3.5 Impute the NA value with Unknown City\n",
    "#   2.3.6 Draw a frequency plot for the complaints in each city\n",
    "#   2.3.7 Create a scatter and hexbin plot of the concentration of complaints across Brooklyn\n",
    "\n",
    "df_311.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2. Perform basic data exploratory analysis:\n",
    "# 2.1 Draw a frequency plot to show the number of null values in each column of the DataFrame\n",
    "\n",
    "\n",
    "def plot_task2(df_311: df_311):\n",
    "    if df_311.isnull().sum().sum() != 0:\n",
    "        na_df = (df_311.isnull().sum() / len(df_311)) * 100 \n",
    "        #print(na_df)     \n",
    "        na_df = na_df.drop(na_df[na_df == 0].index).sort_values(ascending=False)\n",
    "        missing_data = pd.DataFrame({'Missing Ratio %' : na_df})\n",
    "        missing_data.plot(kind = \"barh\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No NAs found')\n",
    "plot_task2(df_311)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.2 Missing value treatment\n",
    "# 2.2.1 Remove the records whose Closed Date values are null\n",
    "df_cd_nul = df_311[df_311['Closed Date'].notnull()]\n",
    "\n",
    "df_cd_nul[\"Closed Date\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2.3 Analyze the date column, and remove entries that have an incorrect timeline\n",
    "#  2.3.1 Calculate the time elapsed in closed and creation date\n",
    "#  2.3.2 Convert the calculated date to seconds to get a better representation\n",
    "\n",
    "import datetime\n",
    "\n",
    "df_time = pd.read_csv ('Datasets/311_Service_Requests_from_2010_to_Present.csv', parse_dates=['Created Date','Closed Date'])\n",
    "\n",
    "df_time['timeElapsed'] = df_time['Closed Date'] - df_time['Created Date']\n",
    "\n",
    "#print(df['timeElapsed'])\n",
    "\n",
    "df_time['seconds'] = df_time['timeElapsed'].dt.total_seconds()\n",
    "print(df_time['seconds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.3 View the descriptive statistics for the newly created column\n",
    "print(df_time['seconds'].describe().apply(lambda x: format(x, 'f')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.4 Check the number of null values in the Complaint_Type and City columns\n",
    "print(\"Number Complaint Type with null value = \", df_311[\"Complaint Type\"].isnull().sum())\n",
    "print(\"Number City with null value = \", df_311['City'].isnull().sum())\n",
    "#print(\"Number City with NA value = \", df_311['City'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.5 Impute the NA value with Unknown City\n",
    "\n",
    "df_311['City'].fillna(\"Unknown City\", inplace=True)\n",
    "print(\"Number City with NA value = \", df_311['City'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.6 Draw a frequency plot for the complaints in each city\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Total complaints')\n",
    "sns.countplot(y='City',data=df_311)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.7 A Create a scatter and hexbin plot of the concentration of complaints across Brooklyn\n",
    "df_311[['Longitude', 'Latitude']].plot(kind = 'scatter', x='Longitude', y='Latitude', title = 'Complaints Concentration in Brooklyn', figsize = (10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3.7 B\n",
    "df_311[['Longitude', 'Latitude']].plot(kind = 'hexbin', x='Longitude', y='Latitude', gridsize=40,\n",
    "    colormap = 'jet', mincnt=1, title = 'Complaints Concentration in Brooklyn', figsize = (10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 Find major types of complaints:\n",
    "# Task 3.1 Plot a bar graph to show the types of complaints\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Complaints Types Distribution')\n",
    "sns.countplot(y='Complaint Type', data=df_311)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.2 Check the frequency of various types of complaints for New York City\n",
    "df_ny = df_311.loc[df_311['City'] == 'NEW YORK']\n",
    "#df_ny['Complaint Type'].value_counts().head(21).plot(kind='bar', title = 'Complaint Frequency in New York')\n",
    "print(df_ny.describe())\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Complaint Frequency in New York')\n",
    "sns.countplot(y='Complaint Type', data=df_ny)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.3 Find the top 10 complaint types\n",
    "df_top10 = df_311['Complaint Type'].value_counts().head(10)\n",
    "print(df_top10)\n",
    "df_top10.plot(kind='bar',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.4 Display the various types of complaints in each city\n",
    "df1 = pd.crosstab(df_311['City'],df_311['Complaint Type'])\n",
    "\n",
    "df1.plot(kind='bar',stacked=True,figsize=(16,8))\n",
    "plt.title('Complaints per city')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.5 Create a DataFrame, df_new, which contains cities as columns and complaint types in rows\n",
    "df_new = pd.crosstab(df_311['Complaint Type'],df_311['City'])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Visualize the major types of complaints in each city\n",
    "    #4.1 Draw another chart that shows the types of complaints in each city in a single chart, where different colors show the different types of complaints\n",
    "df1.plot(kind='bar',stacked=True,figsize=(16,8))\n",
    "plt.title('Complaints per city')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Sort the complaint types based on the average Request_Closing_Time grouping them for different locations\n",
    "# First We need to create a new TimeDelta Columns as 'Request_Closing_Time' which will be the difference of 'Closed Date' and 'Created Date'.\n",
    "exclude_columns = ['Created Date','Closed Date']\n",
    "\n",
    "for col in exclude_columns:\n",
    "    df_311[col] = pd.to_datetime(df_311[col],format='%m/%d/%Y %I:%M:%S %p')\n",
    "    \n",
    "for col in df_311.columns:\n",
    "    if df_311[col].nunique() < 300 and col not in exclude_columns:\n",
    "        df_311[col] = df_311[col].astype('category')\n",
    "        \n",
    "\n",
    "\n",
    "#print(df['timeElapsed'])\n",
    "\n",
    "# filtering the rows where Complaint Type is Ferry Complaint\n",
    "df_Search= df_311[df_311['Complaint Type'].str.contains('Ferry Complaint')]\n",
    "#print(df_Search)\n",
    "\n",
    "# convert date to seconds\n",
    "df_311['Request_Closing_Time'] = (df_time['Closed Date'] - df_time['Created Date'])\n",
    "df_311['Request_Closing_Time'] = df_311['Request_Closing_Time'].dt.total_seconds()\n",
    "#print(df_311['Request_Closing_Time'])\n",
    "#df_311['Request_Closing_Time'].head()\n",
    "\n",
    "# Dropping the Unspecified Borough\n",
    "df_311 = df_311[df_311[\"Borough\"].str.contains(\"Unspecified\") == False]\n",
    "\n",
    "df_CT = df_311.groupby(['Complaint Type','Borough'])['Request_Closing_Time'].mean()\n",
    "df_CT = df_CT.sort_values(axis=0, ascending=False, inplace=False, kind='quicksort', na_position='first')\n",
    "\n",
    "df_CT = df_CT.dropna()\n",
    "# suppress scientific notation \n",
    "#pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(df_CT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. See whether the average response time across different complaint types is similar (overall)\n",
    "    #5.1 Visualize the average of Request_Closing_Time\n",
    "\n",
    "df_CT = df_CT/1000\n",
    "CT_plot = df_CT.plot(kind='bar', figsize=(20,7))\n",
    "CT_plot.set_xlabel(\"Complaint Type\")\n",
    "CT_plot.set_ylabel(\"Request Closing Time X 1000 (Seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Identify the significant variables by performing statistical analysis using p-values\n",
    "#7. Perform a Kruskal-Wallis H test\n",
    "#7.1 Fail to reject H0: All sample distributions are equal\n",
    "#7.2 Reject H0: One or more sample distributions are not equal\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    " # Storing mean response time for various complaint types\n",
    "complaints = df_311['Complaint Type'].value_counts().index \n",
    "for i in range(len(complaints)):\n",
    "    exec(\"sample{} = df_311.loc[(df_311['Complaint Type'] == '{}') , 'Request_Closing_Time']\".format(i+1 ,complaints[i]))\n",
    "   \n",
    "   \n",
    "#for i in range(len(complaints)):\n",
    "    #exec(\"sample{} = df_311.loc[(df_311['Complaint Type'] == '{}') , 'Request_Closing_Time']\".format(i+1 ,complaints[i]))\n",
    "\n",
    "\n",
    "print (stats.kruskal(sample1,sample2,sample3,sample4,sample5,sample6,sample7,sample8,sample9,sample10,sample11,sample12,sample13,sample14,sample15,sample16,sample17,sample18,sample19,sample20,sample21, nan_policy='omit'))\n",
    "\n",
    "print (\"\\n Assuming testing at Confidence level(95%) => alpha value = 0.05 \\n pvalue (0.0) < alpha value (0.05) There is some significant relation between type of complaint and location (i.e) The type of complaint or service requested and the location are related\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
